output_global_parent_dir: results
output_dir: rloo_rho1b_gsm8k
run_name: rloo_rho1b_gsm8k
dataset_name: openai/gsm8k
dataset_test_split: test
# max_length: 512
bf16: True
torch_dtype: bfloat16
## ppo stuff
rloo_k: 8
temperature: 0.6
kl_coef: 1e-4
total_episodes: 131072
response_length: 400
num_ppo_epochs: 2
num_mini_batches: 1
learning_rate: 1.0e-6
per_device_train_batch_size: 16
gradient_accumulation_steps: 32
model_name_or_path: realtreetune/rho-1b-sft-GSM8K
sft_model_path: realtreetune/rho-1b-sft-GSM8K
local_rollout_forward_batch_size: 128
non_eos_penalty: True
stop_token: eos
# evaluation_strategy: "steps"
# eval_steps: 0.2
## save strategy
save_strategy: steps
save_steps: 0.25
hub_strategy: all_checkpoints
logging_steps: 100
num_sample_generations: 5
