output_global_parent_dir: results
output_dir: ppo_pythia410m_gsm8k
run_name: ppo_pythia410m_gsm8k
dataset_name: openai/gsm8k
dataset_test_split: test
# max_length: 512
bf16: True
torch_dtype: bfloat16
## ppo stuff
num_ppo_epochs: 1
total_episodes: 131072
response_length: 53
num_ppo_epochs: 1
num_mini_batches: 1
learning_rate: 3.0e-6
per_device_train_batch_size: 1
gradient_accumulation_steps: 16
model_name_or_path: realtreetune/rho-1b-sft-GSM8K
sft_model_path: realtreetune/rho-1b-sft-GSM8K
local_rollout_forward_batch_size: 4
non_eos_penalty: True
stop_token: eos
# evaluation_strategy: "steps"
# eval_steps: 0.2
## save strategy
save_strategy: steps
save_steps: 0.25
hub_strategy: all_checkpoints
logging_steps: 100
num_sample_generations: 5
